# Parameters data acquisition
acquisition:
  mode_video: Camera # Video, Camera
  cam_id: 0 # Camera id (if mode_video = Camera); otherwise, video path (if mode_video = Video)
  num_frames: None # Number of frames to acquire; None = infinite
  fps: 30 # Frames per second
  #resolution: (640, 480) # Resolution of the frames
  #crop: None # Crop the frames; None = no crop
  #crop_size: (100, 100) # Crop size
  #crop_position: (0, 0) # Crop position
  downsample: False # Downsample the frames
  downsample_rate: 2 # Downsample rate
  flip: False # Flip the frames
  rotate: False # Rotate the frames
  rotate_angle: 0 # Rotate angle  
  mode_contrast: False # Increase the contrast of the frames
  contrast_gamma: 0.5 # Contrast gamma
  black_and_white: False # Convert the frames to black and white
  mode_ref_mean: True # Reference frame; False = no reference frame
  num_frames_mean: 100 # Number of frames to calculate the reference frame  

# Object detection:

# Default model:
# yolov8
  # model: yolov8 
  # model_format: yolov8 
  # path_model: models/yolov8n_float32_tflite/yolov8n_float32.tflite  
  # path_labels: data/coco-labels/coco-labels-paper.txt  
  # require_labels: True 
  # dtype: tf.float32 
  # signatures:  
  # output_keys: 
  # score_thres: 0.5 

# mobilenet_v2:
#   model: mobilenet_v2
#   model_format: hub 
#   path_model: https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 
#   set TFHUB_CACHE_DIR to locate download; /tmp/tfhub_modules
#   path_labels: openimages_v4 # not relevant
#   score_thres: 0.4 
#   require_labels: False
#   dtype: tf.float32

# yolov3_tf:
  # model: yolov3 
  # model_format: yolov3_tf 
  # path_model: models/yolov3_tf/yolov3.weights  
  # path_labels:  # openimages_v4 (80 classes)
  # require_labels: False 
  # #conf_thres: 0.5 
  # #nms_thres: 0.5 
  # dtype: tf.float32 
  # signatures: 
  # output_keys: 
  # score_thres: 0.4 

# yolov8 (Default model):
#   model: yolov8 
#   model_format: yolov8
#   path_model: models/yolov8n_float32_tflite/yolov8n_float32.tflite, models/yolov8n_saved_model
#   path_labels:  data/coco-labels/coco-labels-paper.txt 
#   score_thres: 0.5
#   require_labels: False
#   dtype: tf.float32

# mobilenet_v2:
#   0.1-0.2s per frame
  # model: mobilenet_v2 
  # model_format: hub 
  # path_model: https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1  
  # path_labels: data/coco-labels/coco-labels-paper.txt    
  # require_labels: False 
  # dtype: tf.float32 
  # signatures: default 
  # output_keys: 
  #   detection_boxes: detection_boxes
  #   detection_scores: detection_scores
  #   detection_classes: detection_class_labels # int
  #   detection_class_entities: detection_class_entities # string
  #   num_detections: 

# efficientdet_lite4:
# 0.3-0.4s
  # model: efficientdet_lite4 
  # model_format: hub 
  # path_model: https://tfhub.dev/tensorflow/efficientdet/lite4/detection/1  # Uncomment first time
  # path_labels: data/coco-labels/coco-labels-paper.txt    
  # require_labels: True 
   # #conf_thres: 0.5 
  # #nms_thres: 0.5 
  # dtype: tf.uint8 
  # signatures:  
  # output_keys: 
  #   detection_boxes: detection_boxes
  #   detection_scores: detection_scores
  #   detection_classes: detection_classes # int
  #   #detection_class_entities:  # string
  #   num_detections: num_detections

detection: 
  model: yolov8 # yolov8, mobilenet_v2, yolov3, efficientdet_lite4
  model_format: yolov8 # tflite, pb, hub, yolov8, yolov3_tf
  # Path to the weights: 
  path_model: models/yolov8n_float32_tflite/yolov8n_float32.tflite  # Uncomment first time
  #cfg: cfg/yolov8.cfg # Path to the cfg
  path_labels: data/coco-labels/coco-labels-paper.txt  # coco
  require_labels: True # Require a label: object detection provides index, which must be converted to label
  #conf_thres: 0.5 # Confidence threshold
  #nms_thres: 0.5 # Non-maximum suppression threshold
  dtype: tf.float32 # tf.float32, tf.uint8
  signatures:  # input/output specifications (model def not available)
  output_keys: 
  #  detection_boxes: detection_boxes
  #  detection_scores: detection_scores
  #  detection_classes: detection_classes # int
    #detection_class_entities:  # string
  #  num_detections: num_detections
  score_thres: 0.5 # Score threshold

  classes_searched: 
    - person # Classes to search
    - 'Male person'
    - 'Female person'
    - "Child"
    - "Woman"
    - "Man" # IMAGENET
    - "Person"
    - "Human face"
    - "Human hand"
    - "Human head"
    - "Animal"
    - "Bird"
    - "Dog" # COCO
  num_frames_freq: 1 # Number of frames to skip between detections
  task: detect

# Checkpoints: Saving images and videos
checkpoints:
  save_images: True # Save images
  path_save_images: results # Path to save the images; None = no save
  name_save: ai_surv # Name of the images
  save_videos: False # Save videos
  path_save_video: None # Path to save the videos; None = no save
  #save_videos_fps: 30 # Frames per second of the videos
  #save_videos_format: mp4v # Format of the videos

# Display: Displaying images and videos
display:
  mode_display: True # Display images and videos